{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bacterial-consciousness",
   "metadata": {},
   "source": [
    "Copyright Â© 2017-2021 ABBYY Production LLC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sudden-threat",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title\n",
    "# \n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "potential-professional",
   "metadata": {},
   "source": [
    "# Gradient bossting tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "successful-madison",
   "metadata": {},
   "source": [
    "This tutorial contains the following steps:\n",
    "\n",
    "* Download dataset\n",
    "* Compare different boosting builders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "korean-henry",
   "metadata": {},
   "source": [
    "## Download dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constitutional-humanity",
   "metadata": {},
   "source": [
    "*Note*: This section doesn't have any NeoML-specific code. It just downloads dataset from the internet. If you are not running this notebook, you may skip this section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handmade-vegetable",
   "metadata": {},
   "source": [
    "In this tutorial we will use 20newsgroups vectorized dataset from scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cardiac-drilling",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups_vectorized\n",
    "\n",
    "train_data = fetch_20newsgroups_vectorized(subset='train')\n",
    "test_data = fetch_20newsgroups_vectorized(subset='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "computational-timothy",
   "metadata": {},
   "source": [
    "## Compare different boosting builders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dirty-replication",
   "metadata": {},
   "source": [
    "In order to compare different boosting builder types we need to:\n",
    "\n",
    "* Prepare error function\n",
    "* Fix other boosting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "absolute-training",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def accuracy(model, X, y):\n",
    "    \"\"\"Returns the accuracy of model on the given data\"\"\"\n",
    "    correct = sum(1 for label, probs in zip(y, model.classify(X))\n",
    "                  if label == np.argmax(probs))\n",
    "    return float(correct)/len(y)\n",
    "\n",
    "\n",
    "# These arguments will be used for every builder_type\n",
    "shared_kwargs = {\n",
    "    'loss' : 'binomial',\n",
    "    'iteration_count' : 100,\n",
    "    'learning_rate' : 0.1,\n",
    "    'subsample' : 1.,\n",
    "    'subfeature' : 0.25,\n",
    "    'random_seed' : 1234,\n",
    "    'max_depth' : 6,\n",
    "    'max_node_count' : -1,\n",
    "    'l1_reg' : 0.,\n",
    "    'l2_reg' : 1.,\n",
    "    'prune' : 0.,\n",
    "    'thread_count' : 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technological-longitude",
   "metadata": {},
   "source": [
    "Now we'll compare training speed and accuracy of different gradient boosting builders.\n",
    "\n",
    "NeoML has several builder of gradient boostings:\n",
    "\n",
    "* `full` - classic algorithm. If dataset is multi-class it uses one-versus-all approach\n",
    "* `hist` - uses histograms of feature values when deciding to split node\n",
    "* `multi_full` - classic with one modification: it always builds one ensemble, where each regressor performs regression with multiple values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "hollow-battlefield",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full  Accuracy: 0.7868  Time: 111.54 sec.\n",
      "hist  Accuracy: 0.7926  Time: 198.95 sec.\n",
      "multi_full  Accuracy: 0.6609  Time: 209.08 sec.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import neoml\n",
    "\n",
    "# Train and test boosting for every builder type\n",
    "for builder in ['full', 'hist', 'multi_full']:\n",
    "    start = time.time()\n",
    "    boost_kwargs = { **shared_kwargs, 'builder_type' : builder}\n",
    "    classifier = neoml.GradientBoost.GradientBoostClassifier(**boost_kwargs)\n",
    "    model = classifier.train(train_data.data, train_data.target)\n",
    "    run_time = time.time() - start\n",
    "    acc = accuracy(model, test_data.data, test_data.target)\n",
    "    print(f'{builder}  Accuracy: {acc:.4f}  Time: {run_time:.2f} sec.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
