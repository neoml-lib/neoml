{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bacterial-consciousness",
   "metadata": {},
   "source": [
    "Copyright Â© 2017-2021 ABBYY Production LLC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sudden-threat",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title\n",
    "# \n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "potential-professional",
   "metadata": {},
   "source": [
    "# Gradient tree boosting classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "successful-madison",
   "metadata": {},
   "source": [
    "[Download the tutorial as a Jupyter notebook](https://github.com/neoml-lib/neoml/blob/master/NeoML/docs/en/Python/tutorials/Boosting.ipynb)\n",
    "\n",
    "In this tutorial, we'll use a NeoML gradient boosting classifier to process the [20newsgroups dataset](http://qwone.com/~jason/20Newsgroups/). We'll compare different modes for building the decision trees, looking at the time it takes to train each one and the accuracy of its performance on the testing set.\n",
    "\n",
    "The tutorial includes the following steps:\n",
    "\n",
    "* [Download the dataset](#Download-the-dataset)\n",
    "* [Compare different builder types](#Compare-different-builder-types)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "korean-henry",
   "metadata": {},
   "source": [
    "## Download the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constitutional-humanity",
   "metadata": {},
   "source": [
    "*Note:* This section doesn't have any NeoML-specific code. It just downloads the dataset from the internet. If you are not running this notebook, you may [skip](#Compare-different-builder-types) this section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handmade-vegetable",
   "metadata": {},
   "source": [
    "The **20newsgroups** vectorized dataset can be downloaded from scikit-learn, ready divided into training and testing subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cardiac-drilling",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups_vectorized\n",
    "\n",
    "train_data = fetch_20newsgroups_vectorized(subset='train')\n",
    "test_data = fetch_20newsgroups_vectorized(subset='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "computational-timothy",
   "metadata": {},
   "source": [
    "## Compare different builder types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dirty-replication",
   "metadata": {},
   "source": [
    "To compare different boosting builder types, we need first to:\n",
    "\n",
    "* Prepare an error function\n",
    "* Set up the other boosting parameters, the same for each builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "absolute-training",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def accuracy(model, X, y):\n",
    "    \"\"\"Returns the accuracy of model on the given data\"\"\"\n",
    "    correct = sum(1 for label, probs in zip(y, model.classify(X))\n",
    "                  if label == np.argmax(probs))\n",
    "    return float(correct)/len(y)\n",
    "\n",
    "\n",
    "# These arguments will be used for every builder_type\n",
    "shared_kwargs = {\n",
    "    'loss' : 'binomial',\n",
    "    'iteration_count' : 100,\n",
    "    'learning_rate' : 0.1,\n",
    "    'subsample' : 1.,\n",
    "    'subfeature' : 0.25,\n",
    "    'random_seed' : 1234,\n",
    "    'max_depth' : 6,\n",
    "    'max_node_count' : -1,\n",
    "    'l1_reg' : 0.,\n",
    "    'l2_reg' : 1.,\n",
    "    'prune' : 0.,\n",
    "    'thread_count' : 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technological-longitude",
   "metadata": {},
   "source": [
    "Now we'll compare training speed and accuracy of different decision tree builders.\n",
    "\n",
    "NeoML has several builder types for gradient boosting:\n",
    "\n",
    "* `full` - classic algorithm. If the dataset has multiple classes it uses one-versus-all approach.\n",
    "* `hist` uses histograms of feature values when deciding to split nodes.\n",
    "* `multi_full` - classic with one modification: for multiple classes it has multiple values in leaf nodes of one tree ensemble, instead of multiple one-versus-all ensembles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "hollow-battlefield",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full  Accuracy: 0.7868  Time: 111.54 sec.\n",
      "hist  Accuracy: 0.7926  Time: 198.95 sec.\n",
      "multi_full  Accuracy: 0.6609  Time: 209.08 sec.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import neoml\n",
    "\n",
    "# Train and test gradient boosting for every builder type\n",
    "for builder in ['full', 'hist', 'multi_full']:\n",
    "    start = time.time()\n",
    "    boost_kwargs = { **shared_kwargs, 'builder_type' : builder}\n",
    "    classifier = neoml.GradientBoost.GradientBoostClassifier(**boost_kwargs)\n",
    "    model = classifier.train(train_data.data, train_data.target)\n",
    "    run_time = time.time() - start\n",
    "    acc = accuracy(model, test_data.data, test_data.target)\n",
    "    print(f'{builder}  Accuracy: {acc:.4f}  Time: {run_time:.2f} sec.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
