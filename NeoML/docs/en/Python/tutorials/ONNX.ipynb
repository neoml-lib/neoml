{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43f83a1a-44aa-4e4c-b335-f82b6bc3853f",
   "metadata": {},
   "source": [
    "Copyright Â© 2017-2023 ABBYY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2da23f57-5e20-47da-be07-5c7b85b995c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title\n",
    "# \n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6f84b4-1df2-40f6-ae5c-05133b802273",
   "metadata": {},
   "source": [
    "# Import from ONNX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ac4c54-0def-4712-bbd5-4f495847abdb",
   "metadata": {},
   "source": [
    "[Download the tutorial as a Jupyter notebook](https://github.com/neoml-lib/neoml/blob/master/NeoML/docs/en/Python/tutorials/ONNX.ipynb)\n",
    "\n",
    "In this tutorial, we'll import an ONNX model to NeoML and validate the its' return. We'll also test additional more advanced settings of ONNX import.\n",
    "\n",
    "The tutorial includes the following steps:\n",
    "\n",
    "* [Download the model](#Download-the-model)\n",
    "* [Import with deffault settings](#Import-with-default-setttings)\n",
    "* [Import with different layouts](#Import-with-different-layouts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0bcf8b-7769-48f3-827c-0ac8eb2e4bbb",
   "metadata": {},
   "source": [
    "## Download the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e18079-daeb-4073-ae04-e3b0bfa945c0",
   "metadata": {},
   "source": [
    "For this tutorial we will use MobilNetV2 model from ONNX model zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50731a03-174d-4172-bda9-eddb6e45a0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = 'https://github.com/onnx/models/raw/main/vision/classification/mobilenet/model/mobilenetv2-12.onnx'\n",
    "file_name = 'mobilenetv2.onnx'\n",
    "\n",
    "with requests.get(url, stream=True) as url_stream:\n",
    "    url_stream.raise_for_status()\n",
    "    with open(file_name, 'wb') as file_out:\n",
    "        for chunk in url_stream.iter_content(chunk_size=8192):\n",
    "            file_out.write(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92969d61-b472-4247-9702-68b0335dacc6",
   "metadata": {},
   "source": [
    "## Import with default settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ac7191-cb4c-406d-b143-2c22da08030a",
   "metadata": {},
   "source": [
    "ONNX uses tensors with variable number of dimensions. NeoML uses blobs with fixed number of dimensions (7). The default way ONNX input and output tensors are emulated in NeoML is by using first dimensions of NeoML blobs.\n",
    "\n",
    "This model has 1 ONNX input named `input` and 1 ONNX output named `output`.\n",
    "\n",
    "The `input` expects `batch_size x 3 x 224 x 224` ONNX tensor which means `batch_size x 3 x 224 x 224 x 1 x 1 x 1` NeoML blob.\n",
    "\n",
    "The `output` will be `batch_size x 1000` ONNX tensor which means `batch_size x 1000 x 1 x 1 x 1 x 1 x 1` NeoML blob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32f2a0f7-f021-40f2-a825-c220c5a75052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the model with default settings\n",
    "import neoml\n",
    "\n",
    "math_engine = neoml.MathEngine.default_math_engine()\n",
    "default_model, model_info = neoml.Onnx.load_from_file(file_name, math_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0829eaa7-cf6b-4f57-acfc-a17ad33d2e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape is  (1, 1000, 1, 1, 1, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "# generate some input data\n",
    "import numpy as np\n",
    "input_data = np.linspace(0.0, 1.0, num=3 * 224 * 224, dtype=np.float32)\n",
    "input_data.resize(1, 3, 224, 224)\n",
    "input_blob = neoml.Blob.asblob(math_engine, input_data, [1, 3, 224, 224, 1, 1, 1])\n",
    "\n",
    "output_blob = default_model.run({model_info['inputs'][0]:input_blob})[model_info['outputs'][0]]\n",
    "print('output shape is ', output_blob.shape)\n",
    "default_output = output_blob.asarray(copy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e3305a-4801-4d27-9d76-1518b4314e93",
   "metadata": {},
   "source": [
    "## Import with different layouts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38f33f0-5a38-43c9-8cbd-7c04b2e97deb",
   "metadata": {},
   "source": [
    "There is another difference between NeoML and ONNX. ONNX works with channel-first (NCHW) image format. NeoML works with channel-last (NHWC).\n",
    "\n",
    "NeoOnnx will import the model in a way that input and output blobs will be having the same dimension order as ONNX inputs and outputs. But this will cause inputs to be transposed inside the network.\n",
    "\n",
    "In cases when your pipeline allows to feed or get images in channel-last format you can import ONNX model with assumption that images will be in channel-last format and will result in a more optimal NeoML model.\n",
    "\n",
    "In order to do this we need to use **layouts**. Layout of an ONNX tensor is an array of NeoML blob dimensions. The length of layout is equal to the number of dimensions of ONNX dimensions. `layouts[i]` sets in which blob dimension ONNX tensor's i'th dimension must be put.\n",
    "\n",
    "Default layout for 4-dimensional ONNX tensor is 'first 4 dims of blob' which is equivalent to `layout = ['batch_length', 'batch_width', 'list_size', 'height']`.\n",
    "\n",
    "But `batch_size x 3 x 224 x 224` ONNX tensor is actually a batch of RGB images. So when first ONNX tensor's dim is a batch, second is `channels`, third is `height` and the last is `width` NeoML won't be doing any additional transpositions and transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c25f0b79-6f72-4e3d-a27c-9744d85e2a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max diff between opt and default outputs:  0.0\n"
     ]
    }
   ],
   "source": [
    "to_channel_last = ['batch_width', 'channels', 'height', 'width']\n",
    "\n",
    "opt_model, model_info = neoml.Onnx.load_from_file(file_name, math_engine, input_layouts={'input' : to_channel_last})\n",
    "# with new layout expected blob is 1 x batch_size x 1 x 224 x 224 x 1 x 3\n",
    "# and we need to transpose data from numpy accordingly\n",
    "input_blob = neoml.Blob.asblob(math_engine, input_data.transpose((0, 2, 3, 1)), [1, 1, 1, 224, 224, 1, 3])\n",
    "\n",
    "output_blob = opt_model.run({model_info['inputs'][0] : input_blob})[model_info['outputs'][0]]\n",
    "opt_output = output_blob.asarray(copy=True)\n",
    "\n",
    "print('max diff between opt and default outputs: ', np.max(opt_output - default_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce469ea-3db3-44cb-946f-baed4c584974",
   "metadata": {},
   "source": [
    "As you can see, the outputs are equal. Now, let's check how many transforms and tranpositions nets have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "691b2f56-59a1-45ff-865c-d2517210791c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default\n",
      "\ttranposes:  2\n",
      "\ttranforms:  2\n",
      "optimized\n",
      "\ttranposes:  1\n",
      "\ttranforms:  1\n"
     ]
    }
   ],
   "source": [
    "def print_onnx_helper_stat(net_name, dnn):\n",
    "    n_transposes = 0\n",
    "    n_transforms = 0\n",
    "    for _, layer in dnn.layers.items():\n",
    "        if layer.class_name == 'NeoMLDnnOnnxTransposeHelper':\n",
    "            n_transposes += 1\n",
    "        elif layer.class_name == 'NeoMLDnnOnnxTransformHelper':\n",
    "            n_transforms += 1\n",
    "    print(net_name)\n",
    "    print('\\ttranposes: ', n_transposes)\n",
    "    print('\\ttranforms: ', n_transforms)\n",
    "\n",
    "print_onnx_helper_stat('default', default_model)\n",
    "print_onnx_helper_stat('optimized', opt_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0db28d2-e47c-4449-a386-6eb9cc89de37",
   "metadata": {},
   "source": [
    "Providing input images as channel-last resulted in less conversions and transpositions!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
