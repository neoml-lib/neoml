{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "stuffed-decimal",
   "metadata": {},
   "source": [
    "Copyright Â© 2017-2021 ABBYY Production LLC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "satisfied-assistant",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title\n",
    "# \n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "speaking-vertex",
   "metadata": {},
   "source": [
    "# Linear regressor tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automotive-italian",
   "metadata": {},
   "source": [
    "This tutorial contains the following steps:\n",
    "\n",
    "* Download dataset\n",
    "* Search for optimal regressor parameters\n",
    "* Evaluate the regresor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decent-lincoln",
   "metadata": {},
   "source": [
    "## Download dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "included-engineering",
   "metadata": {},
   "source": [
    "Note: This section doesn't have any NeoML-specific code. It just downloads dataset from the internet. If you are not running this notebook, you may [skip](#Search-for-optimal-regressor-parameters) this section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dramatic-pressure",
   "metadata": {},
   "source": [
    "In this tutorial we'll use boston housing prices dataset from scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "preliminary-roommate",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "\n",
    "# Get data\n",
    "X, y = load_boston(return_X_y=True)\n",
    "\n",
    "# Split into train/test\n",
    "test_size = 50\n",
    "X_train, X_test = X[:-test_size], X[-test_size:]\n",
    "y_train, y_test = y[:-test_size], y[-test_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fuzzy-thought",
   "metadata": {},
   "source": [
    "## Search for optimal regressor parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "major-tonight",
   "metadata": {},
   "source": [
    "We'll be searching for optimal parameters by brute-force over the fixed parameter grid.\n",
    "\n",
    "For parameter evaluation we'll be using custom cross-validation.\n",
    "\n",
    "First of all we need to write error function. In this tutorial we're gonna use mean squared error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "buried-cowboy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(a, b):\n",
    "    \"\"\"Mean squared error of 2 arrays\"\"\"\n",
    "    return ((a - b) ** 2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compact-commodity",
   "metadata": {},
   "source": [
    "Then let's write cross-validation data iterator and grid search function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "desperate-distribution",
   "metadata": {},
   "outputs": [],
   "source": [
    "import neoml\n",
    "import itertools\n",
    "\n",
    "\n",
    "def cv_iterator(X, y, n_folds):\n",
    "    \"\"\"Returns X_train, y_train, X_test, y_test for each of the folds\"\"\"\n",
    "    data_size = len(y)\n",
    "    test_size = data_size // n_folds\n",
    "    for i in range(n_folds):\n",
    "        train = list(itertools.chain(range(i*test_size),\n",
    "                                     range((i+1)*test_size, data_size)))\n",
    "        test = range(i*test_size, (i+1)*test_size)\n",
    "        yield X[train], y[train], X[test], y[test]\n",
    "\n",
    "\n",
    "def grid_search(X, y, param_grid, n_folds=5):\n",
    "    \"\"\"Searches for the most optimal parameters in the grid\n",
    "    Returns trained model and optimal parameters\n",
    "    \"\"\"\n",
    "    best_params = {}\n",
    "\n",
    "    if param_grid:  # Avoid corner case when param_grid is empty\n",
    "        param_names, param_values_lists = zip(*param_grid.items())\n",
    "        best_mse = 2. ** 32\n",
    "        for param_values in itertools.product(*param_values_lists):\n",
    "            kwargs = dict(zip(param_names, param_values))\n",
    "            linear = neoml.Linear.LinearRegressor(**kwargs)\n",
    "            avg_mse = 0.\n",
    "            # Calculate average MSE for K-folds\n",
    "            for X_train, y_train, X_test, y_test in cv_iterator(X, y, n_folds):\n",
    "                model = linear.train(X_train, y_train)\n",
    "                avg_mse += mse(y_test, model.predict(X_test))\n",
    "            # Update params if MSE has improved\n",
    "            if avg_mse < best_mse:\n",
    "                best_mse = avg_mse\n",
    "                best_params = kwargs\n",
    "\n",
    "    best_linear = neoml.Linear.LinearRegressor(**best_params)\n",
    "    return best_linear.train(X, y), best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nuclear-young",
   "metadata": {},
   "source": [
    "Now we can search for optimal parameters. The dataset is very small, that's why number of folds in cross-validation need to be huge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "welsh-earth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:  {'error_weight': 0.01, 'l1_reg': 0.0, 'thread_count': 4}\n",
      "Wall time: 22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "param_grid = {\n",
    "    'error_weight': [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1., 1e1, 1e2],\n",
    "    'l1_reg': [0.0, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1],\n",
    "    'thread_count': [4],\n",
    "}\n",
    "\n",
    "# Search for optimal parameters\n",
    "model, params = grid_search(X_train, y_train, param_grid, n_folds=20)\n",
    "\n",
    "print('Best params: ', params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "about-jumping",
   "metadata": {},
   "source": [
    "## Evaluate the regresor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retired-constant",
   "metadata": {},
   "source": [
    "Let's take a look at the results of the regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "empty-president",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(50,)\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(type(y_pred))\n",
    "print(y_pred.shape)\n",
    "print(y_pred.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "persistent-present",
   "metadata": {},
   "source": [
    "The regressor returns the prediction for each object as an 1-dimensional numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "effective-third",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 13.520\n"
     ]
    }
   ],
   "source": [
    "print(f'Test MSE: {mse(y_test, y_pred):.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
