# Введение

Модуль NeoMathEngineAvx предназначен для ускорения отдельных методов NeoML путём реализации их с использованием набора инструкци AVX/AVX2/FMA. Это позволяет запускать код как на уже довольно старых процессорах x86_64 (Haswell и старше), так и на AMD процессорах, поддерживающих соответствующий набор инструкций.

В данный момент в модуле реализовано глобально три подсистемы: прямая свёртка, ядра для матричного умножения и набор различных примитивов, используемых в нейросетях.

Ядра для матричного умножения написаны с применением intrinsic вызовов для использования в классе CMatrixMultiplier. По результатам замеров матричное умножение с использованием данных ядер выигрывает у MKL на AMD процессорах, но в целом проигрывает MKL на Intel даже с тем же набором инструкций AVX/AVX2/FMA.

Прямая свёртка и примитивы реализованы уже с использованием OpenSource библиотеки [xbyak](https://github.com/herumi/xbyak). Эта библиотека позволяет генерировать машинные инструкции в рантайме, поэтому в дальнейшем будем именовать данную технологию **JIT компилятором** или просто **JIT**. Одна из замечательных особенностей xbyak - это простая реализации API, которая позволяет писать код очень приближенный по виду и структуре в синтаксису ассемблера от Intel. Основные преимущества JIT компилятора - это минимизация условных переходов, расчёт всех смещений и подстановка константных значений на этапе компиляции JIT кода, а так же разворачивание циклов для лучшей предвыборки кода конвейером.

# Описание модулей

## Matrix multiplication kernels
Тут чистый C++, смысла описывать этот модуль в данном документе нет.

## Forward convolution
Изначально модуль писался с применением intrinsic вызовов, но впоследствии был переведён на JIT, однако реализация в виде шаблонного класса осталась, хотя в ней уже нет никакой необходимости, так как в целом время на время генерации JIT кода шаблонные параметры не влияют, а после генерации кода шаблоны уже не нужны. *В будущем хорошо бы убрать шаблонные параметры из класса, чтобы упростить код"
JIT код для Forward convolution генерируется отдельно для каждого дескриптора, так как он зависит от различных параметров дескриптора и этот тот самый случай, когда ускорение достигается в том числе при помощи использование в инструкциях известных заранее констант и смещений.
Работа данного модуля уже описывалась для реализации на intrinsic-ах, JIT основгую логику не поменял. О том, как работает JIT будет рассказано в следующем разделе.

## Primitives
JIT - очень необычный способ написания кода, так как с одной стороны логику работы JIT компилятора вы пишете на C++, пользуясь всеми преимуществами и новыми фишками этого языка. С другой стороны вы пишите как бы код на ассемблере, получая компактный и довольно оптимальный код (хотя и не всегда читаемый для неподготовленного программиста). С последнее, самое главное, вы пишете код, зная в каких условиях он будет запускаться, сколько раз, с какими переменными/константами и т.д., тем самым позволяя вам обеспечить максимальную производительность. Данные три аспекта позволяют добиваться значительных успехов в улучшении производительности.

### Подготовка и ссылочные материалы
1. Для начала нужно ознакомится с базовыми аспектами языка Assembler и с его Intel синтаксисом.
2. Нужно почитать документацию на [xbyak](https://github.com/herumi/xbyak), там довольно небольшой объём, и он хорошо структурирован и сопровождён примерами.
3. Для поиска документации на ассемблерные инструкции я пользовался в основном следующими сайтами:
* [x86 and amd64 instruction reference](https://www.felixcloutier.com/x86/index.html)
* [Intel® Intrinsics Guide](https://www.intel.com/content/www/us/en/docs/intrinsics-guide/index.html)
* [X86-64_Instruction_Encoding](https://wiki.osdev.org/X86-64_Instruction_Encoding) - полезно для понимания режима адресации при формировании команд.

Вот, вроде и всё, что нужно для уверенной работы с xbyak.

### Проблемы или особенности, с которыми столкнулись при использовании xbyak
Считаю, что данный раздел следует поместить ДО описания работы с xbyak.

1. В процессе работы нельзя смешивать инструкции AVX и SSE, так как это приводит к фатальному замедление, которое может быть вызвано перезагрузкой модуля SIMD инструкций. Более подробно про этом можно почитать в [Intel® 64 and IA - 32 Architectures Optimization Reference Manual](https://www.intel.com/content/dam/www/public/us/en/documents/manuals/64-ia-32-architectures-optimization-manual.pdf), раздел 11.3 **MIXING AVX CODE WITH SSE CODE**:  
*Assembly/Compiler Coding Rule 72. (H impact, H generality) Add VZEROUPPER instruction after
256-bit AVX instructions are executed and before any function call that might execute SSE code. Add VZEROUPPER at the end of any function that uses 256-bit AVX instructions.*
2. xbyak имеет такую замечательную особенность, что очень трудно сформировать неправильную инструкцию. Внутри вызовов функций имеется множество проверок, которые не позволят вам использовать неправильные операнды внутри инструкции.
3. Получить какой-то прирост скорости при использовании prefetch инструкций очень сложно. Это связано с тем, что современные процессоры имеют очень хорошую аппаратную реализацию поиска закономерностей при доступе к памяти, и автоматически подгружают необходимые блоки.

### Описание класса `CPrimitivesJit`
#### Общие положения
В интерфейсе класса реализованы два механизма вызова функций примитива: непосредственно вызвав метод или получив указатель на конкретный примитив. Первый механизм был сделан при реализации JIT реализации части сетки LSTM, второй механизм позволяет безболезненно подменить вызовы примитивов в классе `CCpuMathEngine`.

Наибольшее ускорение можно достичь для ёмких с точки зрения вычислений операций. По этой причине простые примитивы показывают весьма нестабильное ускорение относительно реализации с sse intrinsic-ами, так как основное время занимает доступ к памяти и в случае промахов кэша результат замера производительности может сильно гулять.

#### Контейнер `gens`, хранящий JIT код функций примитивов
Все реализованные JIT функции перечислены в enum-е `TPrimitive`. В классе определена структура `CGenerator`, которая по сути своей является экземпляром класса Xbyak::CodeGenerator, отвечающий за формирование JIT кода. Массив **`gens`** хранит все сгенерированные JIT примитивы, их генерация происходит при первом обращении к данному примитиву в методе `GetFunctionRawPtr()`.

#### Таблица констант
Так же стоить отметить таблицу констант, которая определяется при помощи ключей **`TTableKey`**, а так же двух контейнеров **`table`** и **`tableOffsets`**. Эта таблица позволяет хранить в одном месте все константы, которые нужны при выполнении JIT кода и иметь к ним лёгкий доступ. Так как невозможно напрямую задать инициализирующее значение `ymm` регистра в коде инструкции, приходится производить загрузку их памяти. Локализация всех констант в одном месте благоприятно сказывается на работе с кэшем.

Таблица констант инициализируется один раз в конструкторе `CPrimitivesJit` вызовом метода `initTable`. В каждой JIT функции адрес таблицы констант (если он используется) находится в регистре `regTablePtr` (**`r10`**), получить адрес для инициализации `ymm` регистра можно при помощи методов `getOfft` или `getAddr`, передавая при этом необходимые смещения. Метод `getAddr` возвращает непосредственный дескриптор адреса `Xbyak::Address` реализующего механизм относительной адресации (относительно регистра `regTablePtr`)

#### Структура функции примитива
JIT примитивы создаются в шаблонном методе `initPrimitive`, который или непосредственно содержит код генерации JIT функции или же является обёрткой для другого шаблонного метода (называется `init...`), который просто обобщает реализацию похожих функций (как правило, это простейшие математические примитивы).
Тем не менее можно выделить следующие обязательные шаги:
* Создание экземпляра класса CGenerator
* Определение регистров, которые должны быть сохранены перед выполнением функции (*`preservedReg64`* и *`preservedYmm`*). Для Windows и Unix это разные наборы регистров, более подробно про них можно узнать в соглашении о выходах для конкретной ОС.
* Вызов обязательного метода `Prologue` в котором добавляется необходимая преамбула для любой функции, на стеке сохраняются необходимые регистры, а также высчитывается дескриптор адреса, указывающий на область стека, содержащую аргументы вызываемой функции (если такие есть)
* Определение регистров, используемых в функции и какими значениями они будут инициализироваться: или регистрами или же значениями из стека, тут тоже важно изучить соглашение о вызовах функции. Так, например, Windows передаёт через регистры только 4 параметра в то время, как Unix передаёт 6. В то же время, если параметры перемежаются значениями с плавающей точкой, то эти значения так же содержаться в разных регистрах Xmm в Windows и Unix. Если параметров функции больше, чем число отведённых на это регистров, то остальные параметры передаются через стек. Ещё в Windows есть такое понятие как ShadowSpace - зарезервированная область на стеке перед аргументами размером в 32 байта.
* Реализация lambda функции, которая выполняет основные вычислительные операции для данного примитива.
* Выполнение пакетной обработки входных значений с разворачиванием циклов (unrolling loop), применяя при этом lambda функцию из предыдущего пункта. Количество элементов которые мы можем развернуть в одном цикле определяется тем, сколько регистров ymm участвует в обработке, а так же тем, сколько элементов содержится в типовых случаях использования. Так например для сложных примитивов `Exp`, `Sigmoid`, `Tanh` и `RestOfLstm`, где задействовано много регистров ymm, мы не обрабатываем за раз более двух значений.
* Выполняем обработку 'хвоста' входных данных, если их длинна не кратна 8. Обработка хвостовых значений отличается только тем, что чтение и запись данных производится по маске.
* Вызов обязательного метода Epilogue, в котором восстанавливаются сохранённые ранее регистры, вызывается обязательная инструкция `VZEROUPPER`, о которой говорилось выше, а также восстанавливается указатели фрейма и стека (инструкция leave).

Для простейших примитивов добавить к предыдущему описанию особо нечего, разве что то, что код, выполняющий пакетную обработку для разного количества входных данных, унифицирован и реализован в функции `insertSimpleMathFunction()`

### Описание сложных примитивов
Сложные примитивы состоят из других примитивов (**Sigmoid** и **RestOfLstm**) или вычисляются при помощи полинома (**Tanh** и **Exp**). Такие примитивы используют много регистров ymm для вычисления одного блока из 8 входных значений, а потому разворачивают за раз как правило не более двух таких блоков.
Но тут возникает такая проблема, что в функции `insertPrimitive` которая обрабатывает два блока (два входных ymm) нам пришлось бы каждую строчку писать дважды, а кроме того иметь ещё такую же функцию, которая обрабатывала только один блок за раз. Подобный подход неминуемо привёл бы к расхождению коду и появлению труднодетектируемых багов, поэтому в этих примитивах мы оперируем не с отдельными `ymm`, а с их вектором `ymmVec_t`, поэтому при инициализации мы или вручную проверяем сколько блоков мы должны обработать:  
`ymmVec_t forget = wholeYmmNumber == 2 ? ymmVec_t{ ymm0, ymm1 } : ymmVec_t{ ymm0 };`  
или используем специальную функцию `initFromAux()`, которая нарезает вектор вспомогательных регистров `ymmAux` на небольшие блоки, каждый из которых по размеру равен размеру входных данных (`ymmSrc`).

Подобное оперирование векторами `ymm` заставило нас перегрузить различные методы класса `Xbyak::CodeGenerator`, отвечающие зв генерацию инструкций. Эти перегруженные функции определены в базовом классе `CJitCommon`. Чтобы иметь возможность перегрузить функцию в одну строчку, пришлось определить ряд дефайнов и шаблонных функций для разного количества и комбинации аргументов. Но как итог мы получили возможность использовать синтаксис, идентичный тому, что есть в xbyak для работы с векторами регистров.

#### Tanh
Вычисление данного примитива подробно расписана в комментариях. Весь диапазон значений аргумента бьётся на отрезки:
1. [0; linear_ubound] линейный участок tanh(x) = x
2. [linear_ubound; 0x1.8p-12] - часть половины бинады   
   [0x1.8p-12; 0x1.0p-11], ..., [0x1.8p2; 0x1.0p3] - 29 половин бинад   
   [0x1.0p3; saturation_ubound]   
   Это 31 интервал, где значение тангенса вычисляется полиномом 6-й степени
3.  [0x1.205966p3; saturation_ubound] - участок насыщения, где tanh(x) = 1

Остальные действия понятны из кода:
1. Отбрасываем знак, чтобы потом добавить его к ответу.
2. Вычисляем какая бинада соответствует данному аргументу
3. Вычисляем значение гиперболического тангенса при помощи полинома
4. Для линейного участка и участка насыщения подставляем x и 1 соответственно
5. Возвращаем знак

#### Exp
Экспонента также вычисляется полиномом. Для вычисления экспоненты мы разбиваем аргумент на две части, поделив его на ln(2).
Результат деления `x / ln(2)` будет целая часть `n` и остаток `r`, таким образом можно обратно выразить:  
`x = n * ln(2) + r`
`exp(x) = exp(n * ln(2) + r) = exp(ln(2))^n * exp(r) = 2^n * exp(r)`   
Таким образом нам необходимо посчитать целую часть и остаток (`n` и `r`), после чего `2^n` считается элементарно сдвигом, а `exp(r)` считается полиномом на отрезке [0;ln(2)].

Перед вычислением экспоненты мы должны ограничить аргумент сверху и снизу, чтобы не получить переполнение. `ExpFltMax` и `ExpFltMin` так же заданы в hex формате, если `ExpFltMax` увеличить на единицу, то при переполнении мы получим `inf`, а это не согласуется с аналогичным результатом у MKL.

Что происходит внутри функции:
1. Сохраняем маску для значение меньше `ExpFltMin`, в конце функции мы по той маске заполним соответствующие результаты нулями.  
	`gen.vcmpltps( ymmMask, ymmSrc, getAddr( TTableKey::ExpFltMin ) );`
2. Ограничиваем аргумент `x` сверху и снизу и кэшируем значение для последующего использования.
	`gen.vminps( ymmSrc, ymmSrc, getAddr( TTableKey::ExpFltMax ) );`
	`gen.vmaxps( ymmSrc, ymmSrc, getAddr( TTableKey::ExpFltMin ) );`
	`gen.vmovups( ymmAux1, ymmSrc );`
3. Вычисляем целую часть от деления `x / ln(2)`, при этом прибавляя `0.5`, чтобы сместить остаток от деления в область нуля для более точного вычисления полинома.
`n = round( x / ln(2) + 0.5) = round( x * log2(e) + 0.5`
4. Вычисляем остаток `r = x - n * ln(2)`
5. В случае, если `n == 128`, мы получим переполнение при вычислении `2^n`, поэтому мы поступим следующим образом:
`exp(x) = 2^n * exp(r) = 2^(n-1) * exp(r) * 2`, выражение `2^(n-1) * exp(r)` будет меньше `2^127` и в итоге переполнения не будет.
Вычислим `2^(n-1)` при помощи операции сдвига, добавив `ExpBias`, чтобы соблюсти формат числа с плавающей точкой:
	`gen.vsubps( ymmSrc, ymmSrc, getAddr( TTableKey::One ) );`
	`gen.vcvtps2dq( ymmAux2, ymmSrc );`
	`gen.vpaddd( ymmAux2, ymmAux2, getAddr( TTableKey::ExpBias ) );`
	`gen.vpslld( ymmAux2, ymmAux2, MantissaNumBits );`
6. Применим маску полученную в шаге 1, обнулив значения, которые меньше `ExpFltMin`
	`gen.vxorps( ymmSrc, ymmSrc, ymmSrc );`
	`gen.vblendvps( ymmAux2, ymmAux2, ymmSrc, ymmMask );`
7. Посчитаем `exp(r)` при помощи полинома
8. Домножим полученное значение сначала на 2^(n-1) потом на 2, чтобы избежать проблемы, полученной в шаге 5.

#### Sigmoid
Примитив sigmoid по определению считается при помощи экспоненты:   
`sigmoid(x) = exp(x) / ( 1 + exp(x) )`
При описании метода `insertPrimitive<Sigmoid>` стоит отметить лишь то, что последний регистр `ymmAux` уже инициализирован единицами. Это сделано потому, что `insertPrimitive<Sigmoid>` также активно используется в методе `insertPrimitive<RestOfLstm>`, и подобное допущение позволяем избежать лишних действий.
Чтобы не порушить концепцию унифицированных методов в `initActivationFunction()` был добавлен параметр `afterPrologue`, который является функциональным объектом и вызывается после добавления пролога. Для примитива сигмоида этот функциональный объект как раз и инициализирует последний `ymmAux` единицами.

#### RestOfLstm
Выглядит реализация данного примитива очень громоздко и страшно, но всё становится более понятным, если взглянуть на схему ***RestOfLstm.pdf*** (***FIXME: хорошо бы эту схему положить внутрь данного .md файла***).

На схеме представлено классическое изображение LSTM ячейки и её реализация в коде, разбитая на три блока. Блоки выбирались из того соображения, чтобы внутри них одновременно использовалось бы максимальное количество регистров `ymm`, но не больше 16 штук. Поэтому каждый блок сопровождён отметкой о количестве используемых регистров (на входе блока/максимальное значение внутри блока/на выходе блока)

Основные вычисления происходят внутри lambda функции `insertCode()`, которая за раз может обрабатывать одно или два входных регистра `ymm`

Так как слой LSTM рекуррентный, то мы имеем внешний цикл, внутри которого выполняется обработка одного шага LSTM ячейки несколькими внутренними циклами, которые просто оптимально обрабатывают данные сначала по 16 значений, потом по 8, потом что осталось.

	// *** Main loop ***
	gen.StartDownCountLoop( regObjectsCount, 1 );
	 Внутренняя обработка одного шага
	// *** Stop Main loop ***
	gen.StopDownCountLoop();

После каждого внутреннего цикла мы обновляем указатели.
Методы `StartDownCountLoop()`/`StopDownCountLoop()` реализованы таким способом, что позволяют организовывать вложенные циклы, сохраняя лэйблы для переходов в стеке и отслеживая уровень вложенности.

# Заключение
В целом работу с JIT примитивами планировалось сделать максимально масштабируемой для возможности добавления новых примитивов, но всё равно код уже заслуживает рефакторинга:
1. Можно оставить механизм доступа к примитивам только через получение указателей и убрать поддержку многопоточности.
2. В простейших математических примитивах был добавлен метод `insertSimpleMathFunction()`, который унифицирует разворачивание циклов для блоков различной длинны и обработку хвостовых значений. Подобный механизм хорошо бы перенести и на сложные примитивы.
